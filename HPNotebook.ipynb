{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -q scikit-learn\n",
    "!pip install -q numpy\n",
    "!pip install -q dask-ml\n",
    "!pip install -q hyperopt\n",
    "!pip install -q optuna\n",
    "!pip install -q dask\n",
    "!pip install -q tensorflow\n",
    "!pip intall -q keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are using Support vector machine to train a classifier\n",
    "\n",
    "Checkout more hyperparameters for SVC here: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "Define more hyperparameters in `param_grid` and play around with search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Search Space\n",
    "\n",
    "# Input your code here to play around with Search Spaces\n",
    "# define more hyperparameters\n",
    "\n",
    "c = 0.001\n",
    "gamma = 1e-10\n",
    "\n",
    "param_grid = {\n",
    "              \"C\": [c*(10**i) for i in range(1,14)],\n",
    "              \"gamma\": [gamma*(10**i) for i in range(1,14)]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'C': 0.01, 'gamma': 1e-09},\n",
       " {'C': 0.01, 'gamma': 1e-08},\n",
       " {'C': 0.01, 'gamma': 1.0000000000000001e-07},\n",
       " {'C': 0.01, 'gamma': 1e-06},\n",
       " {'C': 0.01, 'gamma': 1e-05}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "def make_sets(grid):\n",
    "    \"\"\"function makes all possible set from the grid above\"\"\"\n",
    "    sets = list()\n",
    "    all_hps_vals = [lst for lst in param_grid.values()]\n",
    "    hp_keys = [hp for hp in param_grid.keys()]\n",
    "    val_sets = product(*all_hps_vals)\n",
    "    for val in val_sets:\n",
    "        hp_set = dict()\n",
    "        for idx, hp_key in enumerate(hp_keys):\n",
    "            hp_set[hp_key] = val[idx]\n",
    "        sets.append(hp_set)\n",
    "    return sets\n",
    "\n",
    "make_sets(param_grid)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(clf, grid, X_train, y_train, X_test, y_test):\n",
    "    # iterates over all the sets\n",
    "    all_sets = make_sets(grid)\n",
    "    logs = list()\n",
    "    best_hp_set = {\n",
    "        \"best_test_score\": 0.0\n",
    "    }\n",
    "    for hp_set in all_sets:\n",
    "        log = dict()\n",
    "        model = clf(**hp_set)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score = model.score(X_train, y_train)\n",
    "        test_score = model.score(X_test, y_test)\n",
    "        \n",
    "        log[\"hp\"] = hp_set\n",
    "        log[\"train_score\"] = train_score\n",
    "        log[\"test_score\"] = test_score\n",
    "        \n",
    "        if best_hp_set[\"best_test_score\"]<test_score:\n",
    "            best_hp_set[\"best_test_score\"] = test_score\n",
    "            best_hp_set[\"hp_set\"] = hp_set\n",
    "        \n",
    "        logs.append(log)\n",
    "        \n",
    "    return logs, best_hp_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs, best = grid_search(SVC, param_grid, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Learn Implementaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0,\n",
       "                               100000.0, 1000000.0, 10000000.0, 100000000.0,\n",
       "                               1000000000.0, 10000000000.0],\n",
       "                         &#x27;gamma&#x27;: [1e-09, 1e-08, 1.0000000000000001e-07, 1e-06,\n",
       "                                   1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                                   100.0, 1000.0]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0,\n",
       "                               100000.0, 1000000.0, 10000000.0, 100000000.0,\n",
       "                               1000000000.0, 10000000000.0],\n",
       "                         &#x27;gamma&#x27;: [1e-09, 1e-08, 1.0000000000000001e-07, 1e-06,\n",
       "                                   1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                                   100.0, 1000.0]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SVC(),\n",
       "             param_grid={'C': [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0,\n",
       "                               100000.0, 1000000.0, 10000000.0, 100000000.0,\n",
       "                               1000000000.0, 10000000000.0],\n",
       "                         'gamma': [1e-09, 1e-08, 1.0000000000000001e-07, 1e-06,\n",
       "                                   1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                                   100.0, 1000.0]})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using k fold cross validation, here k=3\n",
    "\n",
    "clf = GridSearchCV(SVC(), param_grid, cv=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=100.0, gamma=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=100.0, gamma=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=100.0, gamma=0.01)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Test Score: {clf.score(X_test, y_test)}')\n",
    "# print(f'Train Score: {clf.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change values here in `param_grid` to play with search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def loguniform(low=0, high=1, size=100, base=10):\n",
    "    \"\"\"function creates a log uniform distribution with \n",
    "    random values.\"\"\"\n",
    "    return np.power(base, np.random.uniform(low, high, size))\n",
    "\n",
    "param_grid = {\n",
    "              \"gamma\": loguniform(low=-10, high=4, base=10),\n",
    "              \"C\": loguniform(low=-3, high=11, base=10)\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_hp_set(grid):\n",
    "      # function chooses a random value for each from grid\n",
    "    hp_set = dict()\n",
    "    for key, param in grid.items():\n",
    "             hp_set[key] = np.random.choice(param) \n",
    "    return hp_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(clf, grid, n_iterations, X_train, y_train, X_test, y_test):\n",
    "# defining function for random search    \n",
    "    logs = list()\n",
    "    best_hp_set = {\n",
    "    \"best_test_score\": 0.0\n",
    "    }\n",
    "\n",
    "    for iteration in range(n_iterations):\n",
    "        log = dict()\n",
    "\n",
    "        # selecting the set of hyperparameters from function defined\n",
    "        # for random search.\n",
    "        hp_set = get_random_hp_set(grid)\n",
    "        # print(hp_set)\n",
    "        model = clf(**hp_set)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score = model.score(X_train, y_train)\n",
    "        test_score = model.score(X_test, y_test)\n",
    "\n",
    "        log[\"hp\"] = hp_set\n",
    "        log[\"train_score\"] = train_score\n",
    "        log[\"test_score\"] = test_score\n",
    "\n",
    "        if best_hp_set[\"best_test_score\"]<test_score:\n",
    "            best_hp_set[\"best_test_score\"] = test_score\n",
    "            best_hp_set[\"hp_set\"] = hp_set\n",
    "\n",
    "        logs.append(log)\n",
    "\n",
    "    return logs, best_hp_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs, best = random_search(SVC, param_grid, 20, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_test_score': 1.0,\n",
       " 'hp_set': {'gamma': 0.00030548136524084335, 'C': 21903676817.243515}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Learn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=SVC(), n_iter=20,\n",
       "                   param_distributions={&#x27;C&#x27;: array([4.83397523e-03, 3.06630664e+02, 2.46192207e+08, 2.01473719e-01,\n",
       "       3.13042218e-03, 5.56258362e-01, 7.57056937e-01, 4.81966514e-01,\n",
       "       7.40446282e+07, 1.75830199e+04, 5.01719159e+00, 9.30305302e-03,\n",
       "       6.29616216e+07, 2.19036768e+10, 7.21121982e+01, 1.68929189e-03,\n",
       "       1.67410938e-02, 2.59492012e+0...\n",
       "       1.55740120e+01, 3.02154412e-06, 1.75542806e-06, 1.98368741e+02,\n",
       "       1.56974424e-09, 1.04703916e+01, 1.54939163e-07, 1.70868633e+02,\n",
       "       1.69117291e-08, 5.72949892e-01, 8.16116815e+03, 2.97444425e-10,\n",
       "       6.18537711e-01, 2.20637034e-04, 5.17878498e+00, 1.15924198e-10,\n",
       "       1.07525300e+02, 4.14621758e-09, 1.88757996e-08, 1.90660972e-09,\n",
       "       2.59764108e+02, 1.53312507e-10, 5.75892917e-10, 2.51081155e-03])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=SVC(), n_iter=20,\n",
       "                   param_distributions={&#x27;C&#x27;: array([4.83397523e-03, 3.06630664e+02, 2.46192207e+08, 2.01473719e-01,\n",
       "       3.13042218e-03, 5.56258362e-01, 7.57056937e-01, 4.81966514e-01,\n",
       "       7.40446282e+07, 1.75830199e+04, 5.01719159e+00, 9.30305302e-03,\n",
       "       6.29616216e+07, 2.19036768e+10, 7.21121982e+01, 1.68929189e-03,\n",
       "       1.67410938e-02, 2.59492012e+0...\n",
       "       1.55740120e+01, 3.02154412e-06, 1.75542806e-06, 1.98368741e+02,\n",
       "       1.56974424e-09, 1.04703916e+01, 1.54939163e-07, 1.70868633e+02,\n",
       "       1.69117291e-08, 5.72949892e-01, 8.16116815e+03, 2.97444425e-10,\n",
       "       6.18537711e-01, 2.20637034e-04, 5.17878498e+00, 1.15924198e-10,\n",
       "       1.07525300e+02, 4.14621758e-09, 1.88757996e-08, 1.90660972e-09,\n",
       "       2.59764108e+02, 1.53312507e-10, 5.75892917e-10, 2.51081155e-03])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=SVC(), n_iter=20,\n",
       "                   param_distributions={'C': array([4.83397523e-03, 3.06630664e+02, 2.46192207e+08, 2.01473719e-01,\n",
       "       3.13042218e-03, 5.56258362e-01, 7.57056937e-01, 4.81966514e-01,\n",
       "       7.40446282e+07, 1.75830199e+04, 5.01719159e+00, 9.30305302e-03,\n",
       "       6.29616216e+07, 2.19036768e+10, 7.21121982e+01, 1.68929189e-03,\n",
       "       1.67410938e-02, 2.59492012e+0...\n",
       "       1.55740120e+01, 3.02154412e-06, 1.75542806e-06, 1.98368741e+02,\n",
       "       1.56974424e-09, 1.04703916e+01, 1.54939163e-07, 1.70868633e+02,\n",
       "       1.69117291e-08, 5.72949892e-01, 8.16116815e+03, 2.97444425e-10,\n",
       "       6.18537711e-01, 2.20637034e-04, 5.17878498e+00, 1.15924198e-10,\n",
       "       1.07525300e+02, 4.14621758e-09, 1.88757996e-08, 1.90660972e-09,\n",
       "       2.59764108e+02, 1.53312507e-10, 5.75892917e-10, 2.51081155e-03])})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomizedSearchCV(SVC(), param_grid, n_iter=20, cv=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=336163088.1545798, gamma=3.13145092305502e-08)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=336163088.1545798, gamma=3.13145092305502e-08)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=336163088.1545798, gamma=3.13145092305502e-08)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Test Score: {clf.score(X_test, y_test)}')\n",
    "# print(f'Train Score: {clf.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the client first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define client such that you don't hang your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanay/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(processes=False, threads_per_worker=4, memory_limit='4GB', n_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://192.168.0.36/72345/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://192.168.0.36:8787/status' target='_blank'>http://192.168.0.36:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>4.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://192.168.0.36/72345/1' processes=1 threads=4, memory=4.00 GB>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `client.dashboard_link` to monitor the distribution over your system cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://192.168.0.36:8787/status'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.dashboard_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll distribute a huge dataset, using Dask package\n",
    "\n",
    "### Let's simply train a model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanay/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/home/tanay/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/home/tanay/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    }
   ],
   "source": [
    "from dask_ml import datasets\n",
    "from dask_ml.model_selection import train_test_split\n",
    "import dask.array as da\n",
    "from dask_ml.wrappers import Incremental\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.make_classification(n_samples=1000000,\n",
    "                                         n_features=7,\n",
    "                                         random_state=0,\n",
    "                                         chunks=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 56.00 MB </td> <td> 5.60 MB </td></tr>\n",
       "    <tr><th> Shape </th><td> (1000000, 7) </td> <td> (100000, 7) </td></tr>\n",
       "    <tr><th> Count </th><td> 10 Tasks </td><td> 10 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"25\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"24\" x2=\"25\" y2=\"24\" />\n",
       "  <line x1=\"0\" y1=\"36\" x2=\"25\" y2=\"36\" />\n",
       "  <line x1=\"0\" y1=\"48\" x2=\"25\" y2=\"48\" />\n",
       "  <line x1=\"0\" y1=\"60\" x2=\"25\" y2=\"60\" />\n",
       "  <line x1=\"0\" y1=\"72\" x2=\"25\" y2=\"72\" />\n",
       "  <line x1=\"0\" y1=\"84\" x2=\"25\" y2=\"84\" />\n",
       "  <line x1=\"0\" y1=\"96\" x2=\"25\" y2=\"96\" />\n",
       "  <line x1=\"0\" y1=\"108\" x2=\"25\" y2=\"108\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,120.0 0.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >7</text>\n",
       "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">1000000</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<normal, shape=(1000000, 7), dtype=float64, chunksize=(100000, 7), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 8.00 MB </td> <td> 800.00 kB </td></tr>\n",
       "    <tr><th> Shape </th><td> (1000000,) </td> <td> (100000,) </td></tr>\n",
       "    <tr><th> Count </th><td> 121 Tasks </td><td> 10 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> int64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"0\" x2=\"12\" y2=\"25\" />\n",
       "  <line x1=\"24\" y1=\"0\" x2=\"24\" y2=\"25\" />\n",
       "  <line x1=\"36\" y1=\"0\" x2=\"36\" y2=\"25\" />\n",
       "  <line x1=\"48\" y1=\"0\" x2=\"48\" y2=\"25\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"60\" y2=\"25\" />\n",
       "  <line x1=\"72\" y1=\"0\" x2=\"72\" y2=\"25\" />\n",
       "  <line x1=\"84\" y1=\"0\" x2=\"84\" y2=\"25\" />\n",
       "  <line x1=\"96\" y1=\"0\" x2=\"96\" y2=\"25\" />\n",
       "  <line x1=\"108\" y1=\"0\" x2=\"108\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1000000</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<astype, shape=(1000000,), dtype=int64, chunksize=(100000,), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = da.unique(y).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that we can only use modeling algorithms which supports Batch Training, to train model in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanay/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Incremental(estimator=SGDClassifier(loss=&#x27;log&#x27;, tol=0.01), scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Incremental</label><div class=\"sk-toggleable__content\"><pre>Incremental(estimator=SGDClassifier(loss=&#x27;log&#x27;, tol=0.01), scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(loss=&#x27;log&#x27;, tol=0.01)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(loss=&#x27;log&#x27;, tol=0.01)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Incremental(estimator=SGDClassifier(loss='log', tol=0.01), scoring='accuracy')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='log', penalty='l2', tol=0.01)\n",
    "# wrapping in Incremental\n",
    "clf = Incremental(clf, scoring='accuracy')\n",
    "clf.fit(X_train, y_train, classes=classes)\n",
    "# while training check Client Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For algorithms like SVC we can not train data in batches.\n",
    "\n",
    "### But hyperparameter Optimization can be distributed, let's see how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple classifier with GridSearch\n",
    "\n",
    "X, y = load_digits().data, load_digits().target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle=True)\n",
    "\n",
    "c = 0.001\n",
    "gamma = 1e-10\n",
    "param_grid = {\n",
    "              \"C\": [c*(10**i) for i in range(1,14)],\n",
    "              \"gamma\": [gamma*(10**i) for i in range(1,14)]\n",
    "             }\n",
    "\n",
    "clf = SVC(kernel='rbf')\n",
    "search = GridSearchCV(clf, param_grid, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **monitor dashboard after executing this next piece of code, and see how grid search is distributed over different cores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.800275325775146\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "with joblib.parallel_backend('dask', scatter=[X_train, y_train]):\n",
    "    model = search.fit(X_train, y_train)\n",
    "print(time.time()-since)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Something like this would not work! Why?\n",
    "\n",
    "### Unfortunately for a dask dataset, you cannot use both, an algorithm which train in batches and optimize hyperparameters as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask_ml import datasets\n",
    "# from dask_ml.wrappers import Incremental\n",
    "# from dask_ml.model_selection import train_test_split, GridSearchCV\n",
    "# from dask_ml.metrics import accuracy_score\n",
    "\n",
    "# from sklearn.metrics import make_scorer\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# import joblib\n",
    "\n",
    "# import dask.array as da\n",
    "# from dask.distributed import Client\n",
    "# client = Client(processes=False)\n",
    "\n",
    "# param_grid = {\n",
    "#               \"loss\": ['hinge', 'log'],\n",
    "#               \"tol\": [1e-2, 1e-3]\n",
    "#              }\n",
    "\n",
    "# X, y = datasets.make_classification(n_samples=100000,\n",
    "#                                     n_features=7,\n",
    "#                                     random_state=0,\n",
    "#                                     chunks=10000)\n",
    "\n",
    "# # providing an accuracy metrics from 'dask_ml'\n",
    "# scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# clf = SGDClassifier()\n",
    "# clf_wrap = Incremental(clf, scoring=scorer)\n",
    "# searh_clf = GridSearchCV(clf_wrap, param_grid, cv=3)\n",
    "\n",
    "# with joblib.parallel_backend('dask'):\n",
    "#     model = searh_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A basic where we are optimizing, f(a,b) = a\\*\\*2 - b\\*\\*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 321.72trial/s, best loss: -3.703622010557403]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import tpe, fmin, hp\n",
    "\n",
    "def objective_func(args):\n",
    "    a = args['a']\n",
    "    b = args['b']    \n",
    "    f = a**2 - b**2\n",
    "    return f\n",
    "\n",
    "range_a = hp.uniform('a', -2, 3)\n",
    "range_b = hp.uniform('b', -1, 2)\n",
    "\n",
    "space = {'a': range_a,\n",
    "            'b': range_b}\n",
    "\n",
    "best = fmin(objective_func, space, algo=tpe.suggest, max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': -0.4843757303942593, 'b': 1.9845004053293553}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Hyperopt to find algorithm and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import tpe, fmin, hp\n",
    "import math as m\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = hp.choice('classifier',[\n",
    "        {'model': 'KNeighborsClassifier',\n",
    "        'param': {'n_neighbors':\n",
    "                        hp.choice('n_neighbors',range(3,11)),\n",
    "        'algorithm':hp.choice('algorithm', ['ball_tree', 'kd_tree']),\n",
    "        'leaf_size':hp.choice('leaf_size', range(1,50)),\n",
    "        'metric':hp.choice('metric', [\"euclidean\", \"manhattan\",\n",
    "                           \"chebyshev\", \"minkowski\"\n",
    "                           ])}\n",
    "        },\n",
    "        {'model': 'SVC',\n",
    "        'param':{'C':hp.loguniform('C', -2*m.log(10), 11*m.log(10)),\n",
    "        'kernel':hp.choice('kernel',['rbf', 'poly', 'sigmoid']),\n",
    "        'degree':hp.choice('degree', range(1,6)),\n",
    "        'gamma':hp.loguniform('gamma', -9*m.log(10), 3*m.log(10))}\n",
    "        }\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:16<00:00,  6.15trial/s, best loss: -0.9981481481481481]\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data,\n",
    "                                                    digits.target,\n",
    "                                                    test_size=0.3)\n",
    "\n",
    "logs = {'args':list(),\n",
    "        'train_score': list(),\n",
    "        'val_score': list()}\n",
    "\n",
    "def objective_func(args):\n",
    "    clf_func = args[\"model\"]\n",
    "    params = args[\"param\"]\n",
    "    \n",
    "    # debugging with hyperopt is a pain, so be smart and use these statements when stuck\n",
    "#     print(args)\n",
    "    clf = eval(clf_func)(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    val_score = clf.score(X_test, y_test)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    \n",
    "    logs['args'].append(args)\n",
    "    logs['train_score'].append(train_score)\n",
    "    logs['val_score'].append(val_score)\n",
    "    \n",
    "    return -val_score\n",
    "\n",
    "best = fmin(objective_func, space, algo=tpe.suggest, max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 104313200.80236481,\n",
       " 'classifier': 1,\n",
       " 'degree': 4,\n",
       " 'gamma': 7.341558334446171e-05,\n",
       " 'kernel': 0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try and optimize a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8913333415985107                                   \n",
      "Model: \"sequential\"                                  \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      " Layer (type)                Output Shape              Param #   \n",
      "\n",
      "=================================================================\n",
      "\n",
      " layer_units_1 (Dense)       (None, 64)                50240     \n",
      "\n",
      " layer_units_2 (Dense)       (None, 128)               8320      \n",
      "\n",
      " dropout_p_2 (Dropout)       (None, 128)               0         \n",
      "\n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "\n",
      " layer_units_3 (Dense)       (None, 64)                8256      \n",
      "\n",
      " dropout_p_3 (Dropout)       (None, 64)                0         \n",
      "\n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "\n",
      " layer_units_4 (Dense)       (None, 64)                4160      \n",
      "\n",
      " dropout_p_4 (Dropout)       (None, 64)                0         \n",
      "\n",
      " activation_4 (Activation)   (None, 64)                0         \n",
      "\n",
      " layer_unit_5 (Dense)        (None, 10)                650       \n",
      "\n",
      " activation_5 (Activation)   (None, 10)                0         \n",
      "\n",
      "=================================================================\n",
      "\n",
      "Total params: 71,626                                 \n",
      "\n",
      "Trainable params: 71,626                             \n",
      "\n",
      "Non-trainable params: 0                              \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "0.3824999928474426                                                              \n",
      "Model: \"sequential_1\"                                                           \n",
      "\n",
      "_________________________________________________________________               \n",
      "\n",
      " Layer (type)                Output Shape              Param #                  \n",
      "\n",
      "=================================================================               \n",
      "\n",
      " layer_units_1 (Dense)       (None, 128)               100480                   \n",
      "\n",
      " layer_units_2 (Dense)       (None, 36)                4644                     \n",
      "\n",
      " dropout_p_2 (Dropout)       (None, 36)                0                        \n",
      "\n",
      " activation_2 (Activation)   (None, 36)                0                        \n",
      "\n",
      " layer_units_3 (Dense)       (None, 36)                1332                     \n",
      "\n",
      " dropout_p_3 (Dropout)       (None, 36)                0                        \n",
      "\n",
      " activation_3 (Activation)   (None, 36)                0                        \n",
      "\n",
      " layer_units_4 (Dense)       (None, 16)                592                      \n",
      "\n",
      " dropout_p_4 (Dropout)       (None, 16)                0                        \n",
      "\n",
      " activation_4 (Activation)   (None, 16)                0                        \n",
      "\n",
      " layer_units_5 (Dense)       (None, 256)               4352                     \n",
      "\n",
      " dropout_p_5 (Dropout)       (None, 256)               0                        \n",
      "\n",
      " activation_5 (Activation)   (None, 256)               0                        \n",
      "\n",
      " layer_units_6 (Dense)       (None, 16)                4112                     \n",
      "\n",
      " dropout_p_6 (Dropout)       (None, 16)                0                        \n",
      "\n",
      " activation_6 (Activation)   (None, 16)                0                        \n",
      "\n",
      " layer_unit_7 (Dense)        (None, 10)                170                      \n",
      "\n",
      " activation_7 (Activation)   (None, 10)                0                        \n",
      "\n",
      "=================================================================               \n",
      "\n",
      "Total params: 115,682                                                           \n",
      "\n",
      "Trainable params: 115,682                                                       \n",
      "\n",
      "Non-trainable params: 0                                                         \n",
      "\n",
      "_________________________________________________________________               \n",
      "\n",
      "0.5788333415985107                                                              \n",
      "Model: \"sequential_2\"                                                           \n",
      "\n",
      "_________________________________________________________________               \n",
      "\n",
      " Layer (type)                Output Shape              Param #                  \n",
      "\n",
      "=================================================================               \n",
      "\n",
      " layer_units_1 (Dense)       (None, 512)               401920                   \n",
      "\n",
      " layer_units_2 (Dense)       (None, 128)               65664                    \n",
      "\n",
      " dropout_p_2 (Dropout)       (None, 128)               0                        \n",
      "\n",
      " activation_2 (Activation)   (None, 128)               0                        \n",
      "\n",
      " layer_units_3 (Dense)       (None, 36)                4644                     \n",
      "\n",
      " dropout_p_3 (Dropout)       (None, 36)                0                        \n",
      "\n",
      " activation_3 (Activation)   (None, 36)                0                        \n",
      "\n",
      " layer_units_4 (Dense)       (None, 36)                1332                     \n",
      "\n",
      " dropout_p_4 (Dropout)       (None, 36)                0                        \n",
      "\n",
      " activation_4 (Activation)   (None, 36)                0                        \n",
      "\n",
      " layer_unit_5 (Dense)        (None, 10)                370                      \n",
      "\n",
      " activation_5 (Activation)   (None, 10)                0                        \n",
      "\n",
      "=================================================================               \n",
      "\n",
      "Total params: 473,930                                                           \n",
      "\n",
      "Trainable params: 473,930                                                       \n",
      "\n",
      "Non-trainable params: 0                                                         \n",
      "\n",
      "_________________________________________________________________               \n",
      "\n",
      "0.6607499718666077                                                              \n",
      "Model: \"sequential_3\"                                                           \n",
      "\n",
      "_________________________________________________________________               \n",
      "\n",
      " Layer (type)                Output Shape              Param #                  \n",
      "\n",
      "=================================================================               \n",
      "\n",
      " layer_units_1 (Dense)       (None, 256)               200960                   \n",
      "\n",
      " layer_units_2 (Dense)       (None, 128)               32896                    \n",
      "\n",
      " dropout_p_2 (Dropout)       (None, 128)               0                        \n",
      "\n",
      " activation_2 (Activation)   (None, 128)               0                        \n",
      "\n",
      " layer_units_3 (Dense)       (None, 64)                8256                     \n",
      "\n",
      " dropout_p_3 (Dropout)       (None, 64)                0                        \n",
      "\n",
      " activation_3 (Activation)   (None, 64)                0                        \n",
      "\n",
      " layer_units_4 (Dense)       (None, 36)                2340                     \n",
      "\n",
      " dropout_p_4 (Dropout)       (None, 36)                0                        \n",
      "\n",
      " activation_4 (Activation)   (None, 36)                0                        \n",
      "\n",
      " layer_units_5 (Dense)       (None, 64)                2368                     \n",
      "\n",
      " dropout_p_5 (Dropout)       (None, 64)                0                        \n",
      "\n",
      " activation_5 (Activation)   (None, 64)                0                        \n",
      "\n",
      " layer_units_6 (Dense)       (None, 512)               33280                    \n",
      "\n",
      " dropout_p_6 (Dropout)       (None, 512)               0                        \n",
      "\n",
      " activation_6 (Activation)   (None, 512)               0                        \n",
      "\n",
      " layer_unit_7 (Dense)        (None, 10)                5130                     \n",
      "\n",
      " activation_7 (Activation)   (None, 10)                0                        \n",
      "\n",
      "=================================================================               \n",
      "\n",
      "Total params: 285,230                                                           \n",
      "\n",
      "Trainable params: 285,230                                                       \n",
      "\n",
      "Non-trainable params: 0                                                         \n",
      "\n",
      "_________________________________________________________________               \n",
      "\n",
      "0.10599999874830246                                                             \n",
      "Model: \"sequential_4\"                                                           \n",
      "\n",
      "_________________________________________________________________               \n",
      "\n",
      " Layer (type)                Output Shape              Param #                  \n",
      "\n",
      "=================================================================               \n",
      "\n",
      " layer_units_1 (Dense)       (None, 128)               100480                   \n",
      "\n",
      " layer_units_2 (Dense)       (None, 16)                2064                     \n",
      "\n",
      " dropout_p_2 (Dropout)       (None, 16)                0                        \n",
      "\n",
      " activation_2 (Activation)   (None, 16)                0                        \n",
      "\n",
      " layer_units_3 (Dense)       (None, 64)                1088                     \n",
      "\n",
      " dropout_p_3 (Dropout)       (None, 64)                0                        \n",
      "\n",
      " activation_3 (Activation)   (None, 64)                0                        \n",
      "\n",
      " layer_units_4 (Dense)       (None, 36)                2340                     \n",
      "\n",
      " dropout_p_4 (Dropout)       (None, 36)                0                        \n",
      "\n",
      " activation_4 (Activation)   (None, 36)                0                        \n",
      "\n",
      " layer_units_5 (Dense)       (None, 36)                1332                     \n",
      "\n",
      " dropout_p_5 (Dropout)       (None, 36)                0                        \n",
      "\n",
      " activation_5 (Activation)   (None, 36)                0                        \n",
      "\n",
      " layer_units_6 (Dense)       (None, 512)               18944                    \n",
      "\n",
      " dropout_p_6 (Dropout)       (None, 512)               0                        \n",
      "\n",
      " activation_6 (Activation)   (None, 512)               0                        \n",
      "\n",
      " layer_units_7 (Dense)       (None, 128)               65664                    \n",
      "\n",
      " dropout_p_7 (Dropout)       (None, 128)               0                        \n",
      "\n",
      " activation_7 (Activation)   (None, 128)               0                        \n",
      "\n",
      " layer_units_8 (Dense)       (None, 128)               16512                    \n",
      "\n",
      " dropout_p_8 (Dropout)       (None, 128)               0                        \n",
      "\n",
      " activation_8 (Activation)   (None, 128)               0                        \n",
      "\n",
      " layer_unit_9 (Dense)        (None, 10)                1290                     \n",
      "\n",
      " activation_9 (Activation)   (None, 10)                0                        \n",
      "\n",
      "=================================================================               \n",
      "\n",
      "Total params: 209,714                                                           \n",
      "\n",
      "Trainable params: 209,714                                                       \n",
      "\n",
      "Non-trainable params: 0                                                         \n",
      "\n",
      "_________________________________________________________________               \n",
      "\n",
      "100%|██████████| 5/5 [03:31<00:00, 42.38s/trial, best loss: -0.8913333415985107]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, tpe, fmin\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "# load and preprocess the data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "classes = 10\n",
    "input_shape = 784\n",
    "y_train = np_utils.to_categorical(y_train, classes)\n",
    "y_test = np_utils.to_categorical(y_test, classes)\n",
    "\n",
    "#logs\n",
    "logs = {'model_summary':list(),\n",
    "        'val_acc': list()}\n",
    "\n",
    "def obj_func(args):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #defining first hidden layer\n",
    "    model.add(Dense(units=args['units']['layer_units_1'], \n",
    "                    input_shape=(input_shape, ),\n",
    "                    name='layer_units_1'))\n",
    "    \n",
    "    #defining number of remaining hidden layer\n",
    "    number_of_layers = len(args['units'])\n",
    "    for layer in range(2, number_of_layers):\n",
    "        model.add(Dense(units=args['units'][f'layer_units_{layer}'], \n",
    "                        name=f'layer_units_{layer}'))\n",
    "        model.add(Dropout(args['dropout'][f'dropout_p_{layer}'], \n",
    "                          name=f'dropout_p_{layer}'))\n",
    "        model.add(Activation(activation=args['activation'][f'activation_{layer}'], \n",
    "                             name=f'activation_{layer}'))\n",
    "        \n",
    "    model.add(Dense(classes, name=f'layer_unit_{layer+1}'))\n",
    "    model.add(Activation(activation='softmax', name=f'activation_{layer+1}'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n",
    "                  optimizer='adam')\n",
    "    \n",
    "    result = model.fit(x_train, y_train,\n",
    "                      batch_size=2,\n",
    "                      epochs=1,\n",
    "                      verbose=3,\n",
    "                      validation_split=0.2)\n",
    "    \n",
    "    validation_acc = np.amax(result.history['val_accuracy'])\n",
    "    print(validation_acc)\n",
    "    logs['model_summary'].append(model.summary())\n",
    "    logs['val_acc'].append(validation_acc)\n",
    "    \n",
    "    return -validation_acc\n",
    "\n",
    "def each_layer(number_of_layers):\n",
    "    params = {'units': dict(),\n",
    "              'dropout': dict(),\n",
    "              'activation': dict()}\n",
    "    number_of_nodes = [16,36,64,128,256,512]\n",
    "    for layer in range(number_of_layers):\n",
    "        params['units'][f'layer_units_{layer}'] = hp.choice(f'layer_{number_of_layers}_{layer}', \n",
    "                                                            number_of_nodes)\n",
    "        params['dropout'][f'dropout_p_{layer}'] = hp.uniform(f'dropout_{number_of_layers}_{layer}', \n",
    "                                                             0, \n",
    "                                                             0.8)\n",
    "        params['activation'][f'activation_{layer}'] = hp.choice(f'activation_{number_of_layers}_{layer}', \n",
    "                                                                ['relu', 'elu'])\n",
    "    return params\n",
    "\n",
    "number_of_layers = [3, 5, 7, 9]\n",
    "space = hp.choice('layers', [each_layer(n) for n in number_of_layers])\n",
    "best = fmin(obj_func, space, algo=tpe.suggest, max_evals=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation_5_0': 1,\n",
       " 'activation_5_1': 0,\n",
       " 'activation_5_2': 1,\n",
       " 'activation_5_3': 0,\n",
       " 'activation_5_4': 1,\n",
       " 'dropout_5_0': 0.1783234965278652,\n",
       " 'dropout_5_1': 0.27846772605080233,\n",
       " 'dropout_5_2': 0.6416050660560999,\n",
       " 'dropout_5_3': 0.3588056762389913,\n",
       " 'dropout_5_4': 0.004524594522497249,\n",
       " 'layer_5_0': 1,\n",
       " 'layer_5_1': 2,\n",
       " 'layer_5_2': 3,\n",
       " 'layer_5_3': 2,\n",
       " 'layer_5_4': 2,\n",
       " 'layers': 1}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of trials are too low here, but we can definitly perform an architecture search using this by increasing the number of trials\n",
    "\n",
    "### Now go ahead and explore this amazing wrapper `Hyperas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train a scikit-learn model with this library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-01 23:20:46,559]\u001b[0m A new study created in memory with name: no-name-88abe121-551a-47a1-abd1-c919e4d6e9e9\u001b[0m\n",
      "\u001b[32m[I 2023-06-01 23:20:46,618]\u001b[0m Trial 0 finished with value: 0.9907407407407407 and parameters: {'classifier': 'RandomForest', 'algorithm': 'kd_tree', 'leaf_size': 42, 'metic': 'euclidean'}. Best is trial 0 with value: 0.9907407407407407.\u001b[0m\n",
      "\u001b[32m[I 2023-06-01 23:20:46,681]\u001b[0m Trial 1 finished with value: 0.9851851851851852 and parameters: {'classifier': 'RandomForest', 'algorithm': 'ball_tree', 'leaf_size': 9, 'metic': 'manhattan'}. Best is trial 0 with value: 0.9907407407407407.\u001b[0m\n",
      "<ipython-input-48-733d150d35b3>:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  c = trial.suggest_loguniform(\"svc_c\", 1e-2, 1e+11)\n",
      "<ipython-input-48-733d150d35b3>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  gamma = trial.suggest_loguniform(\"svc_gamma\", 1e-9, 1e+3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial No.=0, HP_Set={'classifier': 'RandomForest', 'algorithm': 'kd_tree', 'leaf_size': 42, 'metic': 'euclidean'}, Score=0.9907407407407407\n",
      "Best Value =0.9907407407407407\n",
      "Trial No.=1, HP_Set={'classifier': 'RandomForest', 'algorithm': 'ball_tree', 'leaf_size': 9, 'metic': 'manhattan'}, Score=0.9851851851851852\n",
      "Best Value =0.9907407407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-01 23:20:46,864]\u001b[0m Trial 2 finished with value: 0.08518518518518518 and parameters: {'classifier': 'SVC', 'svc_c': 0.040805008020949295, 'svc_gamma': 0.012204897472741817, 'svc_kernel': 'rbf', 'svc_degree': 6}. Best is trial 0 with value: 0.9907407407407407.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial No.=2, HP_Set={'classifier': 'SVC', 'svc_c': 0.040805008020949295, 'svc_gamma': 0.012204897472741817, 'svc_kernel': 'rbf', 'svc_degree': 6}, Score=0.08518518518518518\n",
      "Best Value =0.9907407407407407\n",
      "Best trial  accuracy: 0.9907407407407407\n",
      "parameters for best trail are :\n",
      "classifier: RandomForest\n",
      "algorithm: kd_tree\n",
      "leaf_size: 42\n",
      "metic: euclidean\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data,\n",
    "                                                    digits.target,\n",
    "                                                    test_size=0.3)\n",
    "\n",
    "def log(study, trial):\n",
    "    print(f\"Trial No.={trial.number}, HP_Set={trial.params}, Score={trial.value}\")\n",
    "    print(f\"Best Value ={study.best_value}\")\n",
    "\n",
    "def objective_func(trial):\n",
    "    \n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", [\"SVC\", \"RandomForest\"])\n",
    "    if classifier_name == \"SVC\":\n",
    "        c = trial.suggest_loguniform(\"svc_c\", 1e-2, 1e+11)\n",
    "        gamma = trial.suggest_loguniform(\"svc_gamma\", 1e-9, 1e+3)\n",
    "        kernel = trial.suggest_categorical(\"svc_kernel\", ['rbf','poly','rbf','sigmoid'])\n",
    "        degree = trial.suggest_categorical(\"svc_degree\", range(1,15))\n",
    "        clf = SVC(C=c, gamma=gamma, kernel=kernel, degree=degree)\n",
    "    else:\n",
    "        algorithm = trial.suggest_categorical(\"algorithm\", ['ball_tree', \"kd_tree\"])\n",
    "        leaf_size = trial.suggest_categorical(\"leaf_size\", range(1,50))\n",
    "        metric = trial.suggest_categorical(\"metic\", [\"euclidean\",\"manhattan\", \"chebyshev\",\"minkowski\"])\n",
    "        clf = KNeighborsClassifier(algorithm=algorithm, leaf_size=leaf_size, metric=metric)\n",
    "        \n",
    "    clf.fit(X_train, y_train)\n",
    "    val_acc = clf.score(X_test, y_test)\n",
    "    \n",
    "    return val_acc\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
    "study.optimize(objective_func, n_trials=3, callbacks=[log])\n",
    "best_trial = study.best_trial.value\n",
    "\n",
    "print(f\"Best trial  accuracy: {best_trial}\")\n",
    "print(\"parameters for best trail are :\")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and now a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-01 23:20:47,150]\u001b[0m A new study created in memory with name: no-name-2b21ccd3-bdc2-4a7a-b67c-176f152a3f9c\u001b[0m\n",
      "\u001b[32m[I 2023-06-01 23:20:56,176]\u001b[0m Trial 0 finished with value: 0.9338333606719971 and parameters: {'hidden_layers': 1, 'layer1': 16, 'activation1': 'relu', 'optimizer': 'adam'}. Best is trial 0 with value: 0.9338333606719971.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9338333606719971\n",
      "Trial No.=0, HP_Set={'hidden_layers': 1, 'layer1': 16, 'activation1': 'relu', 'optimizer': 'adam'},           Score=0.9338333606719971\n",
      "Best Value =0.9338333606719971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-1804c6a8cc52>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  model.add(Dropout(trial.suggest_uniform(f'dropout{i+1}', 0, 0.8)))\n",
      "\u001b[32m[I 2023-06-01 23:21:09,331]\u001b[0m Trial 1 finished with value: 0.9224166870117188 and parameters: {'hidden_layers': 3, 'layer1': 16, 'activation1': 'relu', 'layer2': 256, 'dropout2': 0.28041357201665246, 'activation2': 'relu', 'layer3': 256, 'dropout3': 0.4569717270237932, 'activation3': 'relu', 'optimizer': 'rmsprop'}. Best is trial 0 with value: 0.9338333606719971.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9224166870117188\n",
      "Trial No.=1, HP_Set={'hidden_layers': 3, 'layer1': 16, 'activation1': 'relu', 'layer2': 256, 'dropout2': 0.28041357201665246, 'activation2': 'relu', 'layer3': 256, 'dropout3': 0.4569717270237932, 'activation3': 'relu', 'optimizer': 'rmsprop'},           Score=0.9224166870117188\n",
      "Best Value =0.9338333606719971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-01 23:21:19,678]\u001b[0m Trial 2 finished with value: 0.9226666688919067 and parameters: {'hidden_layers': 2, 'layer1': 16, 'activation1': 'relu', 'layer2': 512, 'dropout2': 0.752987647076444, 'activation2': 'relu', 'optimizer': 'rmsprop'}. Best is trial 0 with value: 0.9338333606719971.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9226666688919067\n",
      "Trial No.=2, HP_Set={'hidden_layers': 2, 'layer1': 16, 'activation1': 'relu', 'layer2': 512, 'dropout2': 0.752987647076444, 'activation2': 'relu', 'optimizer': 'rmsprop'},           Score=0.9226666688919067\n",
      "Best Value =0.9338333606719971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-01 23:21:31,311]\u001b[0m Trial 3 finished with value: 0.9340000152587891 and parameters: {'hidden_layers': 3, 'layer1': 16, 'activation1': 'elu', 'layer2': 256, 'dropout2': 0.2854440550096142, 'activation2': 'relu', 'layer3': 64, 'dropout3': 0.29623778176314625, 'activation3': 'relu', 'optimizer': 'adam'}. Best is trial 3 with value: 0.9340000152587891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9340000152587891\n",
      "Trial No.=3, HP_Set={'hidden_layers': 3, 'layer1': 16, 'activation1': 'elu', 'layer2': 256, 'dropout2': 0.2854440550096142, 'activation2': 'relu', 'layer3': 64, 'dropout3': 0.29623778176314625, 'activation3': 'relu', 'optimizer': 'adam'},           Score=0.9340000152587891\n",
      "Best Value =0.9340000152587891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-06-01 23:21:43,495]\u001b[0m Trial 4 finished with value: 0.8494166731834412 and parameters: {'hidden_layers': 4, 'layer1': 8, 'activation1': 'relu', 'layer2': 512, 'dropout2': 0.10321320506851475, 'activation2': 'relu', 'layer3': 64, 'dropout3': 0.18473056180576375, 'activation3': 'relu', 'layer4': 64, 'dropout4': 0.5422709361786545, 'activation4': 'relu', 'optimizer': 'rmsprop'}. Best is trial 3 with value: 0.9340000152587891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8494166731834412\n",
      "Trial No.=4, HP_Set={'hidden_layers': 4, 'layer1': 8, 'activation1': 'relu', 'layer2': 512, 'dropout2': 0.10321320506851475, 'activation2': 'relu', 'layer3': 64, 'dropout3': 0.18473056180576375, 'activation3': 'relu', 'layer4': 64, 'dropout4': 0.5422709361786545, 'activation4': 'relu', 'optimizer': 'rmsprop'},           Score=0.8494166731834412\n",
      "Best Value =0.9340000152587891\n",
      "Best trial  accuracy: 0.9340000152587891\n",
      "parameters for best trail are :\n",
      "hidden_layers: 3\n",
      "layer1: 16\n",
      "activation1: elu\n",
      "layer2: 256\n",
      "dropout2: 0.2854440550096142\n",
      "activation2: relu\n",
      "layer3: 64\n",
      "dropout3: 0.29623778176314625\n",
      "activation3: relu\n",
      "optimizer: adam\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "classes = 10\n",
    "input_shape = 784\n",
    "y_train = np_utils.to_categorical(y_train, classes)\n",
    "y_test = np_utils.to_categorical(y_test, classes)\n",
    "x_train, y_train, x_test, y_test, input_shape, classes\n",
    "\n",
    "def log(study, trial):\n",
    "    print(f\"Trial No.={trial.number}, HP_Set={trial.params}, \\\n",
    "          Score={trial.value}\")\n",
    "    print(f\"Best Value ={study.best_value}\")\n",
    "\n",
    "def objective_func(trial):\n",
    " \n",
    "    model = Sequential()\n",
    "\n",
    "    hidden_layer_unit_choice = [32, 64, 256, 512, 1024]\n",
    "\n",
    "    hidden_layers = trial.suggest_int('hidden_layers', 1, 6)\n",
    "    \n",
    "    model.add(Dense(units=trial.suggest_categorical('layer1', [8, 16]), \n",
    "                    input_shape=(input_shape, ),\n",
    "                    name='dense1'))\n",
    "    model.add(Activation(activation=trial.suggest_categorical(f'activation1',\n",
    "                                                               ['relu', 'elu'])))\n",
    "\n",
    "    for i in range(1, hidden_layers):\n",
    "        \n",
    "        model.add(Dense(units=trial.suggest_categorical(f'layer{i+1}', \n",
    "                                                        hidden_layer_unit_choice)))\n",
    "        model.add(Dropout(trial.suggest_uniform(f'dropout{i+1}', 0, 0.8)))\n",
    "        model.add(Activation(activation=trial.suggest_categorical(f'activation{i+1}', \n",
    "                                                                  ['relu', 'elu'])))\n",
    "\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n",
    "                  optimizer=trial.suggest_categorical('optimizer', ['rmsprop', 'adam', 'sgd']))\n",
    "\n",
    "    result = model.fit(x_train, y_train,\n",
    "                      batch_size=4,\n",
    "                      epochs=1,\n",
    "                      verbose=3,\n",
    "                      validation_split=0.2)\n",
    "\n",
    "    validation_acc = np.amax(result.history['val_accuracy'])\n",
    "    print('Validation accuracy:', validation_acc)\n",
    "\n",
    "    return validation_acc\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
    "# increase the number of trials\n",
    "study.optimize(objective_func, n_trials=5, callbacks=[log])\n",
    "best_trial = study.best_trial.value\n",
    "\n",
    "print(f\"Best trial  accuracy: {best_trial}\")\n",
    "print(\"parameters for best trail are :\")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPE is one of the best Bayesian Hyperparameter Optimization Algorithm out there, now choose your poison Optuna Or HyperOpt?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
