{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are using Support vector machine to train a classifier\n",
    "\n",
    "Checkout more hyperparameters for SVC here: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "Define more hyperparameters in `param_grid` and play around with search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Search Space\n",
    "\n",
    "# Input your code here to play around with Search Spaces\n",
    "# define more hyperparameters\n",
    "\n",
    "c = 0.001\n",
    "gamma = 1e-10\n",
    "\n",
    "param_grid = {\n",
    "              \"C\": [c*(10**i) for i in range(1,14)],\n",
    "              \"gamma\": [gamma*(10**i) for i in range(1,14)]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'C': 0.01, 'gamma': 1e-09},\n",
       " {'C': 0.01, 'gamma': 1e-08},\n",
       " {'C': 0.01, 'gamma': 1.0000000000000001e-07},\n",
       " {'C': 0.01, 'gamma': 1e-06},\n",
       " {'C': 0.01, 'gamma': 1e-05}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "def make_sets(grid):\n",
    "    \"\"\"function makes all possible set from the grid above\"\"\"\n",
    "    sets = list()\n",
    "    all_hps_vals = [lst for lst in param_grid.values()]\n",
    "    hp_keys = [hp for hp in param_grid.keys()]\n",
    "    val_sets = product(*all_hps_vals)\n",
    "    for val in val_sets:\n",
    "        hp_set = dict()\n",
    "        for idx, hp_key in enumerate(hp_keys):\n",
    "            hp_set[hp_key] = val[idx]\n",
    "        sets.append(hp_set)\n",
    "    return sets\n",
    "\n",
    "make_sets(param_grid)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(clf, grid, X_train, y_train, X_test, y_test):\n",
    "    # iterates over all the sets\n",
    "    all_sets = make_sets(grid)\n",
    "    logs = list()\n",
    "    best_hp_set = {\n",
    "        \"best_test_score\": 0.0\n",
    "    }\n",
    "    for hp_set in all_sets:\n",
    "        log = dict()\n",
    "        model = clf(**hp_set)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score = model.score(X_train, y_train)\n",
    "        test_score = model.score(X_test, y_test)\n",
    "        \n",
    "        log[\"hp\"] = hp_set\n",
    "        log[\"train_score\"] = train_score\n",
    "        log[\"test_score\"] = test_score\n",
    "        \n",
    "        if best_hp_set[\"best_test_score\"]<test_score:\n",
    "            best_hp_set[\"best_test_score\"] = test_score\n",
    "            best_hp_set[\"hp_set\"] = hp_set\n",
    "        \n",
    "        logs.append(log)\n",
    "        \n",
    "    return logs, best_hp_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs, best = grid_search(SVC, param_grid, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Learn Implementaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0,\n",
       "                               100000.0, 1000000.0, 10000000.0, 100000000.0,\n",
       "                               1000000000.0, 10000000000.0],\n",
       "                         &#x27;gamma&#x27;: [1e-09, 1e-08, 1.0000000000000001e-07, 1e-06,\n",
       "                                   1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                                   100.0, 1000.0]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0,\n",
       "                               100000.0, 1000000.0, 10000000.0, 100000000.0,\n",
       "                               1000000000.0, 10000000000.0],\n",
       "                         &#x27;gamma&#x27;: [1e-09, 1e-08, 1.0000000000000001e-07, 1e-06,\n",
       "                                   1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                                   100.0, 1000.0]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SVC(),\n",
       "             param_grid={'C': [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0,\n",
       "                               100000.0, 1000000.0, 10000000.0, 100000000.0,\n",
       "                               1000000000.0, 10000000000.0],\n",
       "                         'gamma': [1e-09, 1e-08, 1.0000000000000001e-07, 1e-06,\n",
       "                                   1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0,\n",
       "                                   100.0, 1000.0]})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using k fold cross validation, here k=3\n",
    "\n",
    "clf = GridSearchCV(SVC(), param_grid, cv=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, gamma=1.0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1, gamma=1.0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1, gamma=1.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Test Score: {clf.score(X_test, y_test)}')\n",
    "# print(f'Train Score: {clf.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change values here in `param_grid` to play with search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def loguniform(low=0, high=1, size=100, base=10):\n",
    "    \"\"\"function creates a log uniform distribution with \n",
    "    random values.\"\"\"\n",
    "    return np.power(base, np.random.uniform(low, high, size))\n",
    "\n",
    "param_grid = {\n",
    "              \"gamma\": loguniform(low=-10, high=4, base=10),\n",
    "              \"C\": loguniform(low=-3, high=11, base=10)\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_hp_set(grid):\n",
    "      # function chooses a random value for each from grid\n",
    "    hp_set = dict()\n",
    "    for key, param in grid.items():\n",
    "             hp_set[key] = np.random.choice(param) \n",
    "    return hp_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(clf, grid, n_iterations, X_train, y_train, X_test, y_test):\n",
    "# defining function for random search    \n",
    "    logs = list()\n",
    "    best_hp_set = {\n",
    "    \"best_test_score\": 0.0\n",
    "    }\n",
    "\n",
    "    for iteration in range(n_iterations):\n",
    "        log = dict()\n",
    "\n",
    "        # selecting the set of hyperparameters from function defined\n",
    "        # for random search.\n",
    "        hp_set = get_random_hp_set(grid)\n",
    "        # print(hp_set)\n",
    "        model = clf(**hp_set)\n",
    "        model.fit(X_train, y_train)\n",
    "        train_score = model.score(X_train, y_train)\n",
    "        test_score = model.score(X_test, y_test)\n",
    "\n",
    "        log[\"hp\"] = hp_set\n",
    "        log[\"train_score\"] = train_score\n",
    "        log[\"test_score\"] = test_score\n",
    "\n",
    "        if best_hp_set[\"best_test_score\"]<test_score:\n",
    "            best_hp_set[\"best_test_score\"] = test_score\n",
    "            best_hp_set[\"hp_set\"] = hp_set\n",
    "\n",
    "        logs.append(log)\n",
    "\n",
    "    return logs, best_hp_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs, best = random_search(SVC, param_grid, 20, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_test_score': 0.9666666666666667,\n",
       " 'hp_set': {'gamma': 8.30932889992501e-05, 'C': 5476.079575132255}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Learn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=SVC(), n_iter=20,\n",
       "                   param_distributions={&#x27;C&#x27;: array([5.54914439e+01, 1.39940745e+10, 9.41716781e-03, 3.40826872e+08,\n",
       "       4.76771531e+02, 1.24945513e-03, 2.67843921e-03, 1.00393043e+03,\n",
       "       1.12380727e+08, 2.37605797e+06, 8.06974119e+04, 2.16697911e+10,\n",
       "       4.27927096e+00, 5.15061542e+02, 3.54203858e-01, 2.34443125e+01,\n",
       "       1.61417517e+02, 1.35411911e-0...\n",
       "       3.40653688e-06, 4.18616875e+00, 3.60738594e+02, 1.15085785e-06,\n",
       "       5.29418329e-07, 7.96584091e+03, 5.01602613e-10, 2.33707785e-03,\n",
       "       3.57306491e-03, 2.09595368e+02, 3.39936578e-06, 1.56182188e-10,\n",
       "       2.17986415e-10, 1.04868192e-07, 2.16978025e-04, 8.58891993e-07,\n",
       "       1.17777497e+03, 1.19289466e-08, 3.99671777e-09, 8.43475501e-08,\n",
       "       6.21081966e-09, 2.33897209e-07, 8.48586150e-07, 8.24017757e-09])})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=SVC(), n_iter=20,\n",
       "                   param_distributions={&#x27;C&#x27;: array([5.54914439e+01, 1.39940745e+10, 9.41716781e-03, 3.40826872e+08,\n",
       "       4.76771531e+02, 1.24945513e-03, 2.67843921e-03, 1.00393043e+03,\n",
       "       1.12380727e+08, 2.37605797e+06, 8.06974119e+04, 2.16697911e+10,\n",
       "       4.27927096e+00, 5.15061542e+02, 3.54203858e-01, 2.34443125e+01,\n",
       "       1.61417517e+02, 1.35411911e-0...\n",
       "       3.40653688e-06, 4.18616875e+00, 3.60738594e+02, 1.15085785e-06,\n",
       "       5.29418329e-07, 7.96584091e+03, 5.01602613e-10, 2.33707785e-03,\n",
       "       3.57306491e-03, 2.09595368e+02, 3.39936578e-06, 1.56182188e-10,\n",
       "       2.17986415e-10, 1.04868192e-07, 2.16978025e-04, 8.58891993e-07,\n",
       "       1.17777497e+03, 1.19289466e-08, 3.99671777e-09, 8.43475501e-08,\n",
       "       6.21081966e-09, 2.33897209e-07, 8.48586150e-07, 8.24017757e-09])})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=SVC(), n_iter=20,\n",
       "                   param_distributions={'C': array([5.54914439e+01, 1.39940745e+10, 9.41716781e-03, 3.40826872e+08,\n",
       "       4.76771531e+02, 1.24945513e-03, 2.67843921e-03, 1.00393043e+03,\n",
       "       1.12380727e+08, 2.37605797e+06, 8.06974119e+04, 2.16697911e+10,\n",
       "       4.27927096e+00, 5.15061542e+02, 3.54203858e-01, 2.34443125e+01,\n",
       "       1.61417517e+02, 1.35411911e-0...\n",
       "       3.40653688e-06, 4.18616875e+00, 3.60738594e+02, 1.15085785e-06,\n",
       "       5.29418329e-07, 7.96584091e+03, 5.01602613e-10, 2.33707785e-03,\n",
       "       3.57306491e-03, 2.09595368e+02, 3.39936578e-06, 1.56182188e-10,\n",
       "       2.17986415e-10, 1.04868192e-07, 2.16978025e-04, 8.58891993e-07,\n",
       "       1.17777497e+03, 1.19289466e-08, 3.99671777e-09, 8.43475501e-08,\n",
       "       6.21081966e-09, 2.33897209e-07, 8.48586150e-07, 8.24017757e-09])})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomizedSearchCV(SVC(), param_grid, n_iter=20, cv=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=814884.8978000208, gamma=3.2996879778667784e-06)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=814884.8978000208, gamma=3.2996879778667784e-06)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=814884.8978000208, gamma=3.2996879778667784e-06)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Test Score: {clf.score(X_test, y_test)}')\n",
    "# print(f'Train Score: {clf.score(X_train, y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the client first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define client such that you don't hang your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanay/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(processes=False, threads_per_worker=4, memory_limit='4GB', n_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://192.168.244.37/288814/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://192.168.244.37:8787/status' target='_blank'>http://192.168.244.37:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>4.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://192.168.244.37/288814/1' processes=1 threads=4, memory=4.00 GB>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `client.dashboard_link` to monitor the distribution over your system cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://192.168.244.37:8787/status'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.dashboard_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll distribute a huge dataset, using Dask package\n",
    "\n",
    "### Let's simply train a model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanay/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/home/tanay/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "/home/tanay/anaconda3/lib/python3.8/site-packages/dask/dataframe/utils.py:367: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n"
     ]
    }
   ],
   "source": [
    "from dask_ml import datasets\n",
    "from dask_ml.model_selection import train_test_split\n",
    "import dask.array as da\n",
    "from dask_ml.wrappers import Incremental\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.make_classification(n_samples=100000000,\n",
    "                                         n_features=7,\n",
    "                                         random_state=0,\n",
    "                                         chunks=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 5.60 GB </td> <td> 5.60 MB </td></tr>\n",
       "    <tr><th> Shape </th><td> (100000000, 7) </td> <td> (100000, 7) </td></tr>\n",
       "    <tr><th> Count </th><td> 1000 Tasks </td><td> 1000 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> float64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"75\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"25\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"6\" x2=\"25\" y2=\"6\" />\n",
       "  <line x1=\"0\" y1=\"12\" x2=\"25\" y2=\"12\" />\n",
       "  <line x1=\"0\" y1=\"18\" x2=\"25\" y2=\"18\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"25\" y2=\"25\" />\n",
       "  <line x1=\"0\" y1=\"31\" x2=\"25\" y2=\"31\" />\n",
       "  <line x1=\"0\" y1=\"37\" x2=\"25\" y2=\"37\" />\n",
       "  <line x1=\"0\" y1=\"44\" x2=\"25\" y2=\"44\" />\n",
       "  <line x1=\"0\" y1=\"50\" x2=\"25\" y2=\"50\" />\n",
       "  <line x1=\"0\" y1=\"56\" x2=\"25\" y2=\"56\" />\n",
       "  <line x1=\"0\" y1=\"63\" x2=\"25\" y2=\"63\" />\n",
       "  <line x1=\"0\" y1=\"69\" x2=\"25\" y2=\"69\" />\n",
       "  <line x1=\"0\" y1=\"75\" x2=\"25\" y2=\"75\" />\n",
       "  <line x1=\"0\" y1=\"82\" x2=\"25\" y2=\"82\" />\n",
       "  <line x1=\"0\" y1=\"88\" x2=\"25\" y2=\"88\" />\n",
       "  <line x1=\"0\" y1=\"94\" x2=\"25\" y2=\"94\" />\n",
       "  <line x1=\"0\" y1=\"101\" x2=\"25\" y2=\"101\" />\n",
       "  <line x1=\"0\" y1=\"107\" x2=\"25\" y2=\"107\" />\n",
       "  <line x1=\"0\" y1=\"113\" x2=\"25\" y2=\"113\" />\n",
       "  <line x1=\"0\" y1=\"120\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 25.412616514582485,0.0 25.412616514582485,120.0 0.0,120.0\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"12.706308\" y=\"140.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >7</text>\n",
       "  <text x=\"45.412617\" y=\"60.000000\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,45.412617,60.000000)\">100000000</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<normal, shape=(100000000, 7), dtype=float64, chunksize=(100000, 7), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr>\n",
       "<td>\n",
       "<table>\n",
       "  <thead>\n",
       "    <tr><td> </td><th> Array </th><th> Chunk </th></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><th> Bytes </th><td> 800.00 MB </td> <td> 800.00 kB </td></tr>\n",
       "    <tr><th> Shape </th><td> (100000000,) </td> <td> (100000,) </td></tr>\n",
       "    <tr><th> Count </th><td> 12001 Tasks </td><td> 1000 Chunks </td></tr>\n",
       "    <tr><th> Type </th><td> int64 </td><td> numpy.ndarray </td></tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</td>\n",
       "<td>\n",
       "<svg width=\"170\" height=\"75\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"6\" y1=\"0\" x2=\"6\" y2=\"25\" />\n",
       "  <line x1=\"12\" y1=\"0\" x2=\"12\" y2=\"25\" />\n",
       "  <line x1=\"18\" y1=\"0\" x2=\"18\" y2=\"25\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"25\" />\n",
       "  <line x1=\"31\" y1=\"0\" x2=\"31\" y2=\"25\" />\n",
       "  <line x1=\"37\" y1=\"0\" x2=\"37\" y2=\"25\" />\n",
       "  <line x1=\"44\" y1=\"0\" x2=\"44\" y2=\"25\" />\n",
       "  <line x1=\"50\" y1=\"0\" x2=\"50\" y2=\"25\" />\n",
       "  <line x1=\"56\" y1=\"0\" x2=\"56\" y2=\"25\" />\n",
       "  <line x1=\"63\" y1=\"0\" x2=\"63\" y2=\"25\" />\n",
       "  <line x1=\"69\" y1=\"0\" x2=\"69\" y2=\"25\" />\n",
       "  <line x1=\"75\" y1=\"0\" x2=\"75\" y2=\"25\" />\n",
       "  <line x1=\"82\" y1=\"0\" x2=\"82\" y2=\"25\" />\n",
       "  <line x1=\"88\" y1=\"0\" x2=\"88\" y2=\"25\" />\n",
       "  <line x1=\"94\" y1=\"0\" x2=\"94\" y2=\"25\" />\n",
       "  <line x1=\"101\" y1=\"0\" x2=\"101\" y2=\"25\" />\n",
       "  <line x1=\"107\" y1=\"0\" x2=\"107\" y2=\"25\" />\n",
       "  <line x1=\"113\" y1=\"0\" x2=\"113\" y2=\"25\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >100000000</text>\n",
       "  <text x=\"140.000000\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,140.000000,12.706308)\">1</text>\n",
       "</svg>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<astype, shape=(100000000,), dtype=int64, chunksize=(100000,), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = da.unique(y).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that we can only use modeling algorithms which supports Batch Training, to train model in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanay/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:163: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Incremental(estimator=SGDClassifier(loss=&#x27;log&#x27;, tol=0.01), scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Incremental</label><div class=\"sk-toggleable__content\"><pre>Incremental(estimator=SGDClassifier(loss=&#x27;log&#x27;, tol=0.01), scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(loss=&#x27;log&#x27;, tol=0.01)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(loss=&#x27;log&#x27;, tol=0.01)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Incremental(estimator=SGDClassifier(loss='log', tol=0.01), scoring='accuracy')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SGDClassifier(loss='log', penalty='l2', tol=0.01)\n",
    "# wrapping in Incremental\n",
    "clf = Incremental(clf, scoring='accuracy')\n",
    "clf.fit(X_train, y_train, classes=classes)\n",
    "# while training check Client Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For algorithms like SVC we can not train data in batches.\n",
    "\n",
    "### But hyperparameter Optimization can be distributed, let's see how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple classifier with GridSearch\n",
    "\n",
    "X, y = load_digits().data, load_digits().target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle=True)\n",
    "\n",
    "c = 0.001\n",
    "gamma = 1e-10\n",
    "param_grid = {\n",
    "              \"C\": [c*(10**i) for i in range(1,14)],\n",
    "              \"gamma\": [gamma*(10**i) for i in range(1,14)]\n",
    "             }\n",
    "\n",
    "clf = SVC(kernel='rbf')\n",
    "search = GridSearchCV(clf, param_grid, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### monitor dashboard after executing this next piece of code, and see how grid search is distributed over different cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.529071807861328\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "with joblib.parallel_backend('dask', scatter=[X_train, y_train]):\n",
    "    model = search.fit(X_train, y_train)\n",
    "print(time.time()-since)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfortunately for a large dataset, you cannot use both, an algorithm which train in batches and optimize hyperparameters as well\n",
    "\n",
    "### Something like this would not work! Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask_ml import datasets\n",
    "# from dask_ml.wrappers import Incremental\n",
    "# from dask_ml.model_selection import train_test_split, GridSearchCV\n",
    "# from dask_ml.metrics import accuracy_score\n",
    "\n",
    "# from sklearn.metrics import make_scorer\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# import joblib\n",
    "\n",
    "# import dask.array as da\n",
    "# # from dask.distributed import Client\n",
    "# # client = Client(processes=False)\n",
    "\n",
    "# param_grid = {\n",
    "#               \"loss\": ['hinge', 'log'],\n",
    "#               \"tol\": [1e-2, 1e-3]\n",
    "#              }\n",
    "\n",
    "# X, y = datasets.make_classification(n_samples=100000,\n",
    "#                                     n_features=7,\n",
    "#                                     random_state=0,\n",
    "#                                     chunks=10000)\n",
    "\n",
    "# # providing an accuracy metrics from 'dask_ml'\n",
    "# scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# clf = SGDClassifier(loss='log')\n",
    "# clf_wrap = Incremental(clf, scoring=scorer)\n",
    "# searh_clf = GridSearchCV(clf_wrap, param_grid, cv=3)\n",
    "\n",
    "# with joblib.parallel_backend('dask'):\n",
    "#     model = searh_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A basic where we are optimizing, f(a,b) = a\\*\\*2 - b\\*\\*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 265.17trial/s, best loss: -3.9646943731079674]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import tpe, fmin, hp\n",
    "\n",
    "def objective_func(args):\n",
    "    a = args['a']\n",
    "    b = args['b']    \n",
    "    f = a**2 - b**2\n",
    "    return f\n",
    "\n",
    "range_a = hp.uniform('a', -2, 3)\n",
    "range_b = hp.uniform('b', -1, 2)\n",
    "\n",
    "space = {'a': range_a,\n",
    "            'b': range_b}\n",
    "\n",
    "best = fmin(objective_func, space, algo=tpe.suggest, max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.10372706482801239, 'b': 1.9938539758682936}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Hyperopt to find algorithm and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import tpe, fmin, hp\n",
    "import math as m\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = hp.choice('classifier',[\n",
    "        {'model': 'KNeighborsClassifier',\n",
    "        'param': {'n_neighbors':\n",
    "                        hp.choice('n_neighbors',range(3,11)),\n",
    "        'algorithm':hp.choice('algorithm', ['ball_tree', 'kd_tree']),\n",
    "        'leaf_size':hp.choice('leaf_size', range(1,50)),\n",
    "        'metric':hp.choice('metric', [\"euclidean\", \"manhattan\",\n",
    "                           \"chebyshev\", \"minkowski\"\n",
    "                           ])}\n",
    "        },\n",
    "        {'model': 'SVC',\n",
    "        'param':{'C':hp.loguniform('C', -2*m.log(10), 11*m.log(10)),\n",
    "        'kernel':hp.choice('kernel',['rbf', 'poly', 'sigmoid']),\n",
    "        'degree':hp.choice('degree', range(1,6)),\n",
    "        'gamma':hp.loguniform('gamma', -9*m.log(10), 3*m.log(10))}\n",
    "        }\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:22<00:00,  4.53trial/s, best loss: -0.9925925925925926]\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data,\n",
    "                                                    digits.target,\n",
    "                                                    test_size=0.3)\n",
    "\n",
    "logs = {'args':list(),\n",
    "        'train_score': list(),\n",
    "        'val_score': list()}\n",
    "\n",
    "def objective_func(args):\n",
    "    clf_func = args[\"model\"]\n",
    "    params = args[\"param\"]\n",
    "    \n",
    "    # debugging with hyperopt is a pain, so be smart and use these statements when stuck\n",
    "#     print(args)\n",
    "    clf = eval(clf_func)(**params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    val_score = clf.score(X_test, y_test)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    \n",
    "    logs['args'].append(args)\n",
    "    logs['train_score'].append(train_score)\n",
    "    logs['val_score'].append(val_score)\n",
    "    \n",
    "    return -val_score\n",
    "\n",
    "best = fmin(objective_func, space, algo=tpe.suggest, max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 32.84635448123946,\n",
       " 'classifier': 1,\n",
       " 'degree': 1,\n",
       " 'gamma': 0.0027732611555239942,\n",
       " 'kernel': 0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try and optimize a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10599999874830246                                  \n",
      "Model: \"sequential\"                                  \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      " Layer (type)                Output Shape              Param #   \n",
      "\n",
      "=================================================================\n",
      "\n",
      " layer_units_1 (Dense)       (None, 128)               100480    \n",
      "\n",
      " layer_units_2 (Dense)       (None, 256)               33024     \n",
      "\n",
      " dropout_p_2 (Dropout)       (None, 256)               0         \n",
      "\n",
      " activation_2 (Activation)   (None, 256)               0         \n",
      "\n",
      " layer_units_3 (Dense)       (None, 36)                9252      \n",
      "\n",
      " dropout_p_3 (Dropout)       (None, 36)                0         \n",
      "\n",
      " activation_3 (Activation)   (None, 36)                0         \n",
      "\n",
      " layer_units_4 (Dense)       (None, 36)                1332      \n",
      "\n",
      " dropout_p_4 (Dropout)       (None, 36)                0         \n",
      "\n",
      " activation_4 (Activation)   (None, 36)                0         \n",
      "\n",
      " layer_units_5 (Dense)       (None, 16)                592       \n",
      "\n",
      " dropout_p_5 (Dropout)       (None, 16)                0         \n",
      "\n",
      " activation_5 (Activation)   (None, 16)                0         \n",
      "\n",
      " layer_units_6 (Dense)       (None, 64)                1088      \n",
      "\n",
      " dropout_p_6 (Dropout)       (None, 64)                0         \n",
      "\n",
      " activation_6 (Activation)   (None, 64)                0         \n",
      "\n",
      " layer_units_7 (Dense)       (None, 512)               33280     \n",
      "\n",
      " dropout_p_7 (Dropout)       (None, 512)               0         \n",
      "\n",
      " activation_7 (Activation)   (None, 512)               0         \n",
      "\n",
      " layer_units_8 (Dense)       (None, 16)                8208      \n",
      "\n",
      " dropout_p_8 (Dropout)       (None, 16)                0         \n",
      "\n",
      " activation_8 (Activation)   (None, 16)                0         \n",
      "\n",
      " layer_unit_9 (Dense)        (None, 10)                170       \n",
      "\n",
      " activation_9 (Activation)   (None, 10)                0         \n",
      "\n",
      "=================================================================\n",
      "\n",
      "Total params: 187,426                                \n",
      "\n",
      "Trainable params: 187,426                            \n",
      "\n",
      "Non-trainable params: 0                              \n",
      "\n",
      "_________________________________________________________________\n",
      "\n",
      "0.9242500066757202                                                               \n",
      "Model: \"sequential_1\"                                                            \n",
      "\n",
      "_________________________________________________________________                \n",
      "\n",
      " Layer (type)                Output Shape              Param #                   \n",
      "\n",
      "=================================================================                \n",
      "\n",
      " layer_units_1 (Dense)       (None, 16)                12560                     \n",
      "\n",
      " layer_units_2 (Dense)       (None, 36)                612                       \n",
      "\n",
      " dropout_p_2 (Dropout)       (None, 36)                0                         \n",
      "\n",
      " activation_2 (Activation)   (None, 36)                0                         \n",
      "\n",
      " layer_units_3 (Dense)       (None, 64)                2368                      \n",
      "\n",
      " dropout_p_3 (Dropout)       (None, 64)                0                         \n",
      "\n",
      " activation_3 (Activation)   (None, 64)                0                         \n",
      "\n",
      " layer_units_4 (Dense)       (None, 256)               16640                     \n",
      "\n",
      " dropout_p_4 (Dropout)       (None, 256)               0                         \n",
      "\n",
      " activation_4 (Activation)   (None, 256)               0                         \n",
      "\n",
      " layer_unit_5 (Dense)        (None, 10)                2570                      \n",
      "\n",
      " activation_5 (Activation)   (None, 10)                0                         \n",
      "\n",
      "=================================================================                \n",
      "\n",
      "Total params: 34,750                                                             \n",
      "\n",
      "Trainable params: 34,750                                                         \n",
      "\n",
      "Non-trainable params: 0                                                          \n",
      "\n",
      "_________________________________________________________________                \n",
      "\n",
      "0.9150000214576721                                                               \n",
      "Model: \"sequential_2\"                                                           \n",
      "\n",
      "_________________________________________________________________               \n",
      "\n",
      " Layer (type)                Output Shape              Param #                  \n",
      "\n",
      "=================================================================               \n",
      "\n",
      " layer_units_1 (Dense)       (None, 36)                28260                    \n",
      "\n",
      " layer_units_2 (Dense)       (None, 512)               18944                    \n",
      "\n",
      " dropout_p_2 (Dropout)       (None, 512)               0                        \n",
      "\n",
      " activation_2 (Activation)   (None, 512)               0                        \n",
      "\n",
      " layer_unit_3 (Dense)        (None, 10)                5130                     \n",
      "\n",
      " activation_3 (Activation)   (None, 10)                0                        \n",
      "\n",
      "=================================================================               \n",
      "\n",
      "Total params: 52,334                                                            \n",
      "\n",
      "Trainable params: 52,334                                                        \n",
      "\n",
      "Non-trainable params: 0                                                         \n",
      "\n",
      "_________________________________________________________________               \n",
      "\n",
      "0.9014999866485596                                                              \n",
      "Model: \"sequential_3\"                                                           \n",
      "\n",
      "_________________________________________________________________               \n",
      "\n",
      " Layer (type)                Output Shape              Param #                  \n",
      "\n",
      "=================================================================               \n",
      "\n",
      " layer_units_1 (Dense)       (None, 128)               100480                   \n",
      "\n",
      " layer_units_2 (Dense)       (None, 128)               16512                    \n",
      "\n",
      " dropout_p_2 (Dropout)       (None, 128)               0                        \n",
      "\n",
      " activation_2 (Activation)   (None, 128)               0                        \n",
      "\n",
      " layer_units_3 (Dense)       (None, 256)               33024                    \n",
      "\n",
      " dropout_p_3 (Dropout)       (None, 256)               0                        \n",
      "\n",
      " activation_3 (Activation)   (None, 256)               0                        \n",
      "\n",
      " layer_units_4 (Dense)       (None, 64)                16448                    \n",
      "\n",
      " dropout_p_4 (Dropout)       (None, 64)                0                        \n",
      "\n",
      " activation_4 (Activation)   (None, 64)                0                        \n",
      "\n",
      " layer_unit_5 (Dense)        (None, 10)                650                      \n",
      "\n",
      " activation_5 (Activation)   (None, 10)                0                        \n",
      "\n",
      "=================================================================               \n",
      "\n",
      "Total params: 167,114                                                           \n",
      "\n",
      "Trainable params: 167,114                                                       \n",
      "\n",
      "Non-trainable params: 0                                                         \n",
      "\n",
      "_________________________________________________________________               \n",
      "\n",
      "0.5619999766349792                                                              \n",
      "Model: \"sequential_4\"                                                           \n",
      "\n",
      "_________________________________________________________________               \n",
      "\n",
      " Layer (type)                Output Shape              Param #                  \n",
      "\n",
      "=================================================================               \n",
      "\n",
      " layer_units_1 (Dense)       (None, 16)                12560                    \n",
      "\n",
      " layer_units_2 (Dense)       (None, 36)                612                      \n",
      "\n",
      " dropout_p_2 (Dropout)       (None, 36)                0                        \n",
      "\n",
      " activation_2 (Activation)   (None, 36)                0                        \n",
      "\n",
      " layer_units_3 (Dense)       (None, 512)               18944                    \n",
      "\n",
      " dropout_p_3 (Dropout)       (None, 512)               0                        \n",
      "\n",
      " activation_3 (Activation)   (None, 512)               0                        \n",
      "\n",
      " layer_units_4 (Dense)       (None, 16)                8208                     \n",
      "\n",
      " dropout_p_4 (Dropout)       (None, 16)                0                        \n",
      "\n",
      " activation_4 (Activation)   (None, 16)                0                        \n",
      "\n",
      " layer_units_5 (Dense)       (None, 512)               8704                     \n",
      "\n",
      " dropout_p_5 (Dropout)       (None, 512)               0                        \n",
      "\n",
      " activation_5 (Activation)   (None, 512)               0                        \n",
      "\n",
      " layer_units_6 (Dense)       (None, 36)                18468                    \n",
      "\n",
      " dropout_p_6 (Dropout)       (None, 36)                0                        \n",
      "\n",
      " activation_6 (Activation)   (None, 36)                0                        \n",
      "\n",
      " layer_units_7 (Dense)       (None, 16)                592                      \n",
      "\n",
      " dropout_p_7 (Dropout)       (None, 16)                0                        \n",
      "\n",
      " activation_7 (Activation)   (None, 16)                0                        \n",
      "\n",
      " layer_units_8 (Dense)       (None, 128)               2176                     \n",
      "\n",
      " dropout_p_8 (Dropout)       (None, 128)               0                        \n",
      "\n",
      " activation_8 (Activation)   (None, 128)               0                        \n",
      "\n",
      " layer_unit_9 (Dense)        (None, 10)                1290                     \n",
      "\n",
      " activation_9 (Activation)   (None, 10)                0                        \n",
      "\n",
      "=================================================================               \n",
      "\n",
      "Total params: 71,554                                                            \n",
      "\n",
      "Trainable params: 71,554                                                        \n",
      "\n",
      "Non-trainable params: 0                                                         \n",
      "\n",
      "_________________________________________________________________               \n",
      "\n",
      "100%|██████████| 5/5 [02:54<00:00, 34.88s/trial, best loss: -0.9242500066757202]\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, tpe, fmin\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "# load and preprocess the data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "classes = 10\n",
    "input_shape = 784\n",
    "y_train = np_utils.to_categorical(y_train, classes)\n",
    "y_test = np_utils.to_categorical(y_test, classes)\n",
    "\n",
    "#logs\n",
    "logs = {'model_summary':list(),\n",
    "        'val_acc': list()}\n",
    "\n",
    "def obj_func(args):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #defining first hidden layer\n",
    "    model.add(Dense(units=args['units']['layer_units_1'], \n",
    "                    input_shape=(input_shape, ),\n",
    "                    name='layer_units_1'))\n",
    "    \n",
    "    #defining number of remaining hidden layer\n",
    "    number_of_layers = len(args['units'])\n",
    "    for layer in range(2, number_of_layers):\n",
    "        model.add(Dense(units=args['units'][f'layer_units_{layer}'], \n",
    "                        name=f'layer_units_{layer}'))\n",
    "        model.add(Dropout(args['dropout'][f'dropout_p_{layer}'], \n",
    "                          name=f'dropout_p_{layer}'))\n",
    "        model.add(Activation(activation=args['activation'][f'activation_{layer}'], \n",
    "                             name=f'activation_{layer}'))\n",
    "        \n",
    "    model.add(Dense(classes, name=f'layer_unit_{layer+1}'))\n",
    "    model.add(Activation(activation='softmax', name=f'activation_{layer+1}'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n",
    "                  optimizer='adam')\n",
    "    \n",
    "    result = model.fit(x_train, y_train,\n",
    "                      batch_size=2,\n",
    "                      epochs=1,\n",
    "                      verbose=3,\n",
    "                      validation_split=0.2)\n",
    "    \n",
    "    validation_acc = np.amax(result.history['val_accuracy'])\n",
    "    print(validation_acc)\n",
    "    logs['model_summary'].append(model.summary())\n",
    "    logs['val_acc'].append(validation_acc)\n",
    "    \n",
    "    return -validation_acc\n",
    "\n",
    "def each_layer(number_of_layers):\n",
    "    params = {'units': dict(),\n",
    "              'dropout': dict(),\n",
    "              'activation': dict()}\n",
    "    number_of_nodes = [16,36,64,128,256,512]\n",
    "    for layer in range(number_of_layers):\n",
    "        params['units'][f'layer_units_{layer}'] = hp.choice(f'layer_{number_of_layers}_{layer}', \n",
    "                                                            number_of_nodes)\n",
    "        params['dropout'][f'dropout_p_{layer}'] = hp.uniform(f'dropout_{number_of_layers}_{layer}', \n",
    "                                                             0, \n",
    "                                                             0.8)\n",
    "        params['activation'][f'activation_{layer}'] = hp.choice(f'activation_{number_of_layers}_{layer}', \n",
    "                                                                ['relu', 'elu'])\n",
    "    return params\n",
    "\n",
    "number_of_layers = [3, 5, 7, 9]\n",
    "space = hp.choice('layers', [each_layer(n) for n in number_of_layers])\n",
    "best = fmin(obj_func, space, algo=tpe.suggest, max_evals=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation_5_0': 1,\n",
       " 'activation_5_1': 1,\n",
       " 'activation_5_2': 0,\n",
       " 'activation_5_3': 1,\n",
       " 'activation_5_4': 0,\n",
       " 'dropout_5_0': 0.4600061311697963,\n",
       " 'dropout_5_1': 0.16514474977751653,\n",
       " 'dropout_5_2': 0.13413586890484872,\n",
       " 'dropout_5_3': 0.3693425515016359,\n",
       " 'dropout_5_4': 0.370320416042322,\n",
       " 'layer_5_0': 1,\n",
       " 'layer_5_1': 0,\n",
       " 'layer_5_2': 1,\n",
       " 'layer_5_3': 2,\n",
       " 'layer_5_4': 4,\n",
       " 'layers': 1}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of trials are too low here, but we can definitly perform an architecture search using this by increasing the number of trials\n",
    "\n",
    "### Now go ahead and explore this amazing wrapper `Hyperas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train a scikit-learn model with this library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-13 03:39:50,840]\u001b[0m A new study created in memory with name: no-name-78f0363a-91df-48e0-a1d9-4d9bc6fa5069\u001b[0m\n",
      "\u001b[32m[I 2023-03-13 03:39:50,912]\u001b[0m Trial 0 finished with value: 0.9833333333333333 and parameters: {'classifier': 'RandomForest', 'algorithm': 'ball_tree', 'leaf_size': 16, 'metic': 'minkowski'}. Best is trial 0 with value: 0.9833333333333333.\u001b[0m\n",
      "<ipython-input-47-733d150d35b3>:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  c = trial.suggest_loguniform(\"svc_c\", 1e-2, 1e+11)\n",
      "<ipython-input-47-733d150d35b3>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  gamma = trial.suggest_loguniform(\"svc_gamma\", 1e-9, 1e+3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial No.=0, HP_Set={'classifier': 'RandomForest', 'algorithm': 'ball_tree', 'leaf_size': 16, 'metic': 'minkowski'}, Score=0.9833333333333333\n",
      "Best Value =0.9833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-13 03:39:51,126]\u001b[0m Trial 1 finished with value: 0.8203703703703704 and parameters: {'classifier': 'SVC', 'svc_c': 11865.165644029325, 'svc_gamma': 0.00858615894716739, 'svc_kernel': 'rbf', 'svc_degree': 4}. Best is trial 0 with value: 0.9833333333333333.\u001b[0m\n",
      "<ipython-input-47-733d150d35b3>:22: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  c = trial.suggest_loguniform(\"svc_c\", 1e-2, 1e+11)\n",
      "<ipython-input-47-733d150d35b3>:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  gamma = trial.suggest_loguniform(\"svc_gamma\", 1e-9, 1e+3)\n",
      "\u001b[32m[I 2023-03-13 03:39:51,165]\u001b[0m Trial 2 finished with value: 0.9611111111111111 and parameters: {'classifier': 'SVC', 'svc_c': 193392380.36786938, 'svc_gamma': 0.00032461410484564403, 'svc_kernel': 'poly', 'svc_degree': 9}. Best is trial 0 with value: 0.9833333333333333.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial No.=1, HP_Set={'classifier': 'SVC', 'svc_c': 11865.165644029325, 'svc_gamma': 0.00858615894716739, 'svc_kernel': 'rbf', 'svc_degree': 4}, Score=0.8203703703703704\n",
      "Best Value =0.9833333333333333\n",
      "Trial No.=2, HP_Set={'classifier': 'SVC', 'svc_c': 193392380.36786938, 'svc_gamma': 0.00032461410484564403, 'svc_kernel': 'poly', 'svc_degree': 9}, Score=0.9611111111111111\n",
      "Best Value =0.9833333333333333\n",
      "Best trial  accuracy: 0.9833333333333333\n",
      "parameters for best trail are :\n",
      "classifier: RandomForest\n",
      "algorithm: ball_tree\n",
      "leaf_size: 16\n",
      "metic: minkowski\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data,\n",
    "                                                    digits.target,\n",
    "                                                    test_size=0.3)\n",
    "\n",
    "def log(study, trial):\n",
    "    print(f\"Trial No.={trial.number}, HP_Set={trial.params}, Score={trial.value}\")\n",
    "    print(f\"Best Value ={study.best_value}\")\n",
    "\n",
    "def objective_func(trial):\n",
    "    \n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", [\"SVC\", \"RandomForest\"])\n",
    "    if classifier_name == \"SVC\":\n",
    "        c = trial.suggest_loguniform(\"svc_c\", 1e-2, 1e+11)\n",
    "        gamma = trial.suggest_loguniform(\"svc_gamma\", 1e-9, 1e+3)\n",
    "        kernel = trial.suggest_categorical(\"svc_kernel\", ['rbf','poly','rbf','sigmoid'])\n",
    "        degree = trial.suggest_categorical(\"svc_degree\", range(1,15))\n",
    "        clf = SVC(C=c, gamma=gamma, kernel=kernel, degree=degree)\n",
    "    else:\n",
    "        algorithm = trial.suggest_categorical(\"algorithm\", ['ball_tree', \"kd_tree\"])\n",
    "        leaf_size = trial.suggest_categorical(\"leaf_size\", range(1,50))\n",
    "        metric = trial.suggest_categorical(\"metic\", [\"euclidean\",\"manhattan\", \"chebyshev\",\"minkowski\"])\n",
    "        clf = KNeighborsClassifier(algorithm=algorithm, leaf_size=leaf_size, metric=metric)\n",
    "        \n",
    "    clf.fit(X_train, y_train)\n",
    "    val_acc = clf.score(X_test, y_test)\n",
    "    \n",
    "    return val_acc\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
    "study.optimize(objective_func, n_trials=3, callbacks=[log])\n",
    "best_trial = study.best_trial.value\n",
    "\n",
    "print(f\"Best trial  accuracy: {best_trial}\")\n",
    "print(\"parameters for best trail are :\")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and now a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-13 03:39:51,477]\u001b[0m A new study created in memory with name: no-name-786fb32d-4c77-40c1-8374-e50dc05eaa6d\u001b[0m\n",
      "<ipython-input-48-1804c6a8cc52>:46: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "  model.add(Dropout(trial.suggest_uniform(f'dropout{i+1}', 0, 0.8)))\n",
      "\u001b[32m[I 2023-03-13 03:40:13,204]\u001b[0m Trial 0 finished with value: 0.9300000071525574 and parameters: {'hidden_layers': 4, 'layer1': 16, 'activation1': 'elu', 'layer2': 1024, 'dropout2': 0.253108118573581, 'activation2': 'elu', 'layer3': 512, 'dropout3': 0.27827391653624706, 'activation3': 'relu', 'layer4': 32, 'dropout4': 0.13852709093383445, 'activation4': 'relu', 'optimizer': 'sgd'}. Best is trial 0 with value: 0.9300000071525574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9300000071525574\n",
      "Trial No.=0, HP_Set={'hidden_layers': 4, 'layer1': 16, 'activation1': 'elu', 'layer2': 1024, 'dropout2': 0.253108118573581, 'activation2': 'elu', 'layer3': 512, 'dropout3': 0.27827391653624706, 'activation3': 'relu', 'layer4': 32, 'dropout4': 0.13852709093383445, 'activation4': 'relu', 'optimizer': 'sgd'},           Score=0.9300000071525574\n",
      "Best Value =0.9300000071525574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-13 03:40:24,906]\u001b[0m Trial 1 finished with value: 0.9352499842643738 and parameters: {'hidden_layers': 2, 'layer1': 16, 'activation1': 'elu', 'layer2': 512, 'dropout2': 0.28721228301155755, 'activation2': 'elu', 'optimizer': 'rmsprop'}. Best is trial 1 with value: 0.9352499842643738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9352499842643738\n",
      "Trial No.=1, HP_Set={'hidden_layers': 2, 'layer1': 16, 'activation1': 'elu', 'layer2': 512, 'dropout2': 0.28721228301155755, 'activation2': 'elu', 'optimizer': 'rmsprop'},           Score=0.9352499842643738\n",
      "Best Value =0.9352499842643738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-13 03:40:36,337]\u001b[0m Trial 2 finished with value: 0.8840000033378601 and parameters: {'hidden_layers': 3, 'layer1': 8, 'activation1': 'elu', 'layer2': 32, 'dropout2': 0.7715722557251717, 'activation2': 'elu', 'layer3': 512, 'dropout3': 0.07201000245934851, 'activation3': 'relu', 'optimizer': 'sgd'}. Best is trial 1 with value: 0.9352499842643738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8840000033378601\n",
      "Trial No.=2, HP_Set={'hidden_layers': 3, 'layer1': 8, 'activation1': 'elu', 'layer2': 32, 'dropout2': 0.7715722557251717, 'activation2': 'elu', 'layer3': 512, 'dropout3': 0.07201000245934851, 'activation3': 'relu', 'optimizer': 'sgd'},           Score=0.8840000033378601\n",
      "Best Value =0.9352499842643738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-13 03:40:46,182]\u001b[0m Trial 3 finished with value: 0.909250020980835 and parameters: {'hidden_layers': 1, 'layer1': 8, 'activation1': 'elu', 'optimizer': 'sgd'}. Best is trial 1 with value: 0.9352499842643738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.909250020980835\n",
      "Trial No.=3, HP_Set={'hidden_layers': 1, 'layer1': 8, 'activation1': 'elu', 'optimizer': 'sgd'},           Score=0.909250020980835\n",
      "Best Value =0.9352499842643738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-13 03:40:57,662]\u001b[0m Trial 4 finished with value: 0.9154999852180481 and parameters: {'hidden_layers': 2, 'layer1': 8, 'activation1': 'relu', 'layer2': 64, 'dropout2': 0.21112289544859097, 'activation2': 'relu', 'optimizer': 'adam'}. Best is trial 1 with value: 0.9352499842643738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9154999852180481\n",
      "Trial No.=4, HP_Set={'hidden_layers': 2, 'layer1': 8, 'activation1': 'relu', 'layer2': 64, 'dropout2': 0.21112289544859097, 'activation2': 'relu', 'optimizer': 'adam'},           Score=0.9154999852180481\n",
      "Best Value =0.9352499842643738\n",
      "Best trial  accuracy: 0.9352499842643738\n",
      "parameters for best trail are :\n",
      "hidden_layers: 2\n",
      "layer1: 16\n",
      "activation1: elu\n",
      "layer2: 512\n",
      "dropout2: 0.28721228301155755\n",
      "activation2: elu\n",
      "optimizer: rmsprop\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "classes = 10\n",
    "input_shape = 784\n",
    "y_train = np_utils.to_categorical(y_train, classes)\n",
    "y_test = np_utils.to_categorical(y_test, classes)\n",
    "x_train, y_train, x_test, y_test, input_shape, classes\n",
    "\n",
    "def log(study, trial):\n",
    "    print(f\"Trial No.={trial.number}, HP_Set={trial.params}, \\\n",
    "          Score={trial.value}\")\n",
    "    print(f\"Best Value ={study.best_value}\")\n",
    "\n",
    "def objective_func(trial):\n",
    " \n",
    "    model = Sequential()\n",
    "\n",
    "    hidden_layer_unit_choice = [32, 64, 256, 512, 1024]\n",
    "\n",
    "    hidden_layers = trial.suggest_int('hidden_layers', 1, 6)\n",
    "    \n",
    "    model.add(Dense(units=trial.suggest_categorical('layer1', [8, 16]), \n",
    "                    input_shape=(input_shape, ),\n",
    "                    name='dense1'))\n",
    "    model.add(Activation(activation=trial.suggest_categorical(f'activation1',\n",
    "                                                               ['relu', 'elu'])))\n",
    "\n",
    "    for i in range(1, hidden_layers):\n",
    "        \n",
    "        model.add(Dense(units=trial.suggest_categorical(f'layer{i+1}', \n",
    "                                                        hidden_layer_unit_choice)))\n",
    "        model.add(Dropout(trial.suggest_uniform(f'dropout{i+1}', 0, 0.8)))\n",
    "        model.add(Activation(activation=trial.suggest_categorical(f'activation{i+1}', \n",
    "                                                                  ['relu', 'elu'])))\n",
    "\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n",
    "                  optimizer=trial.suggest_categorical('optimizer', ['rmsprop', 'adam', 'sgd']))\n",
    "\n",
    "    result = model.fit(x_train, y_train,\n",
    "                      batch_size=4,\n",
    "                      epochs=1,\n",
    "                      verbose=3,\n",
    "                      validation_split=0.2)\n",
    "\n",
    "    validation_acc = np.amax(result.history['val_accuracy'])\n",
    "    print('Validation accuracy:', validation_acc)\n",
    "\n",
    "    return validation_acc\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
    "# increase the number of trials\n",
    "study.optimize(objective_func, n_trials=5, callbacks=[log])\n",
    "best_trial = study.best_trial.value\n",
    "\n",
    "print(f\"Best trial  accuracy: {best_trial}\")\n",
    "print(\"parameters for best trail are :\")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPE is one of the best Bayesian Hyperparameter Optimization Algorithm out there, now choose your poison Optuna Or HyperOpt?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
